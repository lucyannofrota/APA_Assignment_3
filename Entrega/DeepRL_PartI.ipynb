{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssxiwwi66Se3"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idJX2upP6O8W",
        "outputId": "b9a34a68-4dad-4971-e8f9-217c17896df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [73.9 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,821 kB]\n",
            "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [833 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,452 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,461 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,898 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,230 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.6 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 13.8 MB in 3s (4,314 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.10).\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libxxf86dga1 x11-utils\n",
            "0 upgraded, 2 newly installed, 0 to remove and 84 not upgraded.\n",
            "Need to get 209 kB of archives.\n",
            "After this operation, 711 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Fetched 209 kB in 1s (378 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 157584 files and directories currently installed.)\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: gym[box2d]==0.17.* in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting pyvirtualdisplay==0.2.*\n",
            "  Downloading PyVirtualDisplay-0.2.5-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: PyOpenGL==3.1.* in /usr/local/lib/python3.7/dist-packages (3.1.5)\n",
            "Collecting PyOpenGL-accelerate==3.1.*\n",
            "  Downloading PyOpenGL-accelerate-3.1.5.tar.gz (538 kB)\n",
            "\u001b[K     |████████████████████████████████| 538 kB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay==0.2.*) (0.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.3.0)\n",
            "Collecting box2d-py~=2.3.5\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]==0.17.*) (0.16.0)\n",
            "Building wheels for collected packages: PyOpenGL-accelerate\n",
            "  Building wheel for PyOpenGL-accelerate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL-accelerate: filename=PyOpenGL_accelerate-3.1.5-cp37-cp37m-linux_x86_64.whl size=1599508 sha256=e1da9ba55eee08b6cc9b7e999bf3d77599c9351453ad147c57f91eaef67ba405\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/f5/6f/169afb3f2d476c5e807f8515b3c9bc9b819c3962316aa804eb\n",
            "Successfully built PyOpenGL-accelerate\n",
            "Installing collected packages: box2d-py, pyvirtualdisplay, PyOpenGL-accelerate\n",
            "  Attempting uninstall: pyvirtualdisplay\n",
            "    Found existing installation: PyVirtualDisplay 2.2\n",
            "    Uninstalling PyVirtualDisplay-2.2:\n",
            "      Successfully uninstalled PyVirtualDisplay-2.2\n",
            "Successfully installed PyOpenGL-accelerate-3.1.5 box2d-py-2.3.8 pyvirtualdisplay-0.2.5\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "# install required system dependencies\n",
        "!apt-get install -y xvfb x11-utils\n",
        "\n",
        "# install required python dependencies (might need to install additional gym extras depending)\n",
        "!pip install gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "Running_in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if Running_in_colab:\n",
        "  sys_name = 'COLAB'\n",
        "else:\n",
        "  sys_name = os.environ['COMPUTERNAME']\n",
        "\n",
        "# Importing Libs\n",
        "\n",
        "if not os.path.exists(\"lib\"):\n",
        "    print(\"LOADING FILES\")\n",
        "\n",
        "    if not os.path.exists(\"lib.zip\"):\n",
        "        !wget -q -O lib.zip https://www.dropbox.com/s/k9trf8pgs8dsyxg/lib.zip?dl=0\n",
        "        \n",
        "    if not os.path.exists(\"lib\"):\n",
        "        !unzip \"/content/lib.zip\" -d \"/content\"\n",
        "        # file_names = os.listdir('/content/lib')\n",
        "        # for file_name in file_names:\n",
        "        #     print(file_name)\n",
        "        #     shutil.move(os.path.join(\n",
        "        #         '/content/lib', file_name), '/content/')"
      ],
      "metadata": {
        "id": "mdfpEN-qz1v-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb371b2-56c2-48c6-b253-018b86ce0c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING FILES\n",
            "Archive:  /content/lib.zip\n",
            "   creating: /content/lib/\n",
            "  inflating: /content/lib/archs.py   \n",
            " extracting: /content/lib/desktop.ini  \n",
            "  inflating: /content/lib/my_tools.py  \n",
            "  inflating: /content/lib/performance_evaluation.py  \n",
            "  inflating: /content/lib/train_loop.py  \n",
            " extracting: /content/lib/__init__.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1O4fl6bwGG_"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "import gym\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import random\n",
        "from gym import wrappers\n",
        "import copy\n",
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "\n",
        "from IPython.core.display import HTML\n",
        "from IPython.core.display import Video\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "import sys\n",
        "Running_in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from lib import archs as archs\n",
        "from lib import performance_evaluation as eval\n",
        "from lib import train_loop as tl\n",
        "from lib import my_tools as mt\n",
        "# !mkdir Checkpoints\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIeU54J8wXkI"
      },
      "outputs": [],
      "source": [
        "#@title Deep RL Replay Buffer\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, size, input_shape,dev):\n",
        "        self.size = size\n",
        "        self.counter = 0\n",
        "        self.state_buffer = torch.zeros((self.size, input_shape))\n",
        "        self.action_buffer = torch.zeros(self.size, dtype=torch.int64)\n",
        "        self.reward_buffer = torch.zeros(self.size)\n",
        "        self.new_state_buffer = torch.zeros((self.size, input_shape))\n",
        "        self.terminal_buffer = torch.zeros(self.size)\n",
        "        self.state_buffer.to(dev)\n",
        "        self.action_buffer.to(dev)\n",
        "        self.reward_buffer.to(dev)\n",
        "        self.new_state_buffer.to(dev)\n",
        "        self.terminal_buffer.to(dev)\n",
        "        self.dev=dev;\n",
        "\n",
        "\n",
        "\n",
        "    def store_tuples(self, state, action, reward, new_state, done):\n",
        "        idx = self.counter % self.size\n",
        "        self.state_buffer[idx] = state\n",
        "        self.action_buffer[idx] = action\n",
        "        self.reward_buffer[idx] = reward\n",
        "        self.new_state_buffer[idx] = new_state\n",
        "        self.terminal_buffer[idx] = done\n",
        "        self.counter += 1\n",
        "\n",
        "    def sample_buffer(self, batch_size):\n",
        "        max_buffer = min(self.counter, self.size)\n",
        "        batch = np.random.choice(max_buffer, batch_size, replace=False)\n",
        "        state_batch = self.state_buffer[batch].to(self.dev)\n",
        "        action_batch = self.action_buffer[batch].to(self.dev)\n",
        "        reward_batch = self.reward_buffer[batch].to(self.dev)\n",
        "        new_state_batch = self.new_state_buffer[batch].to(self.dev)\n",
        "        done_batch = self.terminal_buffer[batch].to(self.dev)\n",
        "\n",
        "        return state_batch, action_batch, reward_batch, new_state_batch, done_batch\n",
        "    def last_buffer(self, batch_size):\n",
        "        state_batch = self.state_buffer[-1:-batch_size].to(self.dev)\n",
        "        action_batch = self.action_buffer[-1:-batch_size].to(self.dev)\n",
        "        reward_batch = self.reward_buffer[-1:-batch_size].to(self.dev)\n",
        "        new_state_batch = self.new_state_buffer[-1:-batch_size].to(self.dev)\n",
        "        done_batch = self.terminal_buffer[-1:-batch_size].to(self.dev)\n",
        "\n",
        "        return state_batch, action_batch, reward_batch, new_state_batch, done_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVwFwJMNxoCw"
      },
      "outputs": [],
      "source": [
        "#@title DQN movie generation (for visual evaluation in Google Colab)\n",
        "\n",
        "def createMovie(Network,path,Filename):\n",
        "    env = gym.make(\"CartPole-v0\")\n",
        "    envX = wrappers.Monitor(env,path+'/'+Filename,force=True)\n",
        "\n",
        "    observation = envX.reset()\n",
        "\n",
        "    i=0\n",
        "    Network.eval()\n",
        "\n",
        "    while True:\n",
        "        envX.render()\n",
        "        \n",
        "        state=torch.Tensor(observation).to(device)\n",
        "      \n",
        "        action = Network.policy(state);\n",
        "             \n",
        "        observation, reward, done, info = envX.step(action.item()) \n",
        "        i=i+1;     \n",
        "        if done: \n",
        "          break;\n",
        "\n",
        "    envX.close()\n",
        "    env.close();\n",
        "    Network.train()\n",
        "    mp4list = glob.glob(path+Filename+'/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        if(Running_in_colab):\n",
        "            ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(encoded.decode('ascii'))))\n",
        "        else:\n",
        "            Video(mp4)\n",
        "    else: \n",
        "        print(\"Could not find video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsEv2cZLwy3e"
      },
      "source": [
        "Initialization and Parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yygleEXxEpG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "5dd2ad08-d3dd-4bef-faad-6cd0cb837d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300 of 2000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a1ab0527a1f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Checkpoints\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mbestNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores100\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTotalEpisodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFreezeCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSaveAtCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreateMovie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxSteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration_threshold_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformance_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/lib/train_loop.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(policy_net, target_net, env, device, TotalEpisodes, FreezeCounter, SaveAtCounter, createMovie, MaxSteps, exploration_threshold, exploration_decay, exploration_threshold_min, buffer, trainModel, file_path)\u001b[0m\n\u001b[1;32m     33\u001b[0m               \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m           \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m           \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-a1ab0527a1f7>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     \u001b[0mstate_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mq_actual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-039977dfbfa0>\u001b[0m in \u001b[0;36msample_buffer\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mstate_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0maction_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mreward_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mnew_state_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_state_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Sim configuration\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "spec = gym.spec(\"CartPole-v0\")\n",
        "\n",
        "\n",
        "\n",
        "inputs=4\n",
        "n_actions=2\n",
        "\n",
        "#hyper-parameters\n",
        "TotalEpisodes=2000\n",
        "MaxSteps=400\n",
        "FreezeCounter=25\n",
        "BatchSize=128\n",
        "exploration_threshold=1\n",
        "exploration_threshold_min=0.01\n",
        "# exploration_decay=0.002\n",
        "discount_factor=0.99\n",
        "SaveAtCounter=200\n",
        "LearningRateDecay=0.99\n",
        "\n",
        "\n",
        "#network DQN\n",
        "\n",
        "buffer = ReplayBuffer(1000000, inputs,device);\n",
        "\n",
        "for arch in [\"DQN\",\"DuelingDQN\",\"DoubleDQN\",\"DoubleDuelingDQN\"]:\n",
        "    file_path__ = mt.create_dir(\"results\",arch)\n",
        "    for n_layers in [4]:\n",
        "        policy_net, target_net = archs.archs(arch,inputs,n_actions,discount_factor,device,n_layers)\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "        target_net.eval()\n",
        "        file_path_ = mt.create_dir(file_path__,\"N\"+str(n_layers)+\"_Layers\")\n",
        "        if(arch == \"DQN\"):\n",
        "          lrlist = [0.001]\n",
        "          expldecay = [0.002]\n",
        "        if(arch == \"DuelingDQN\"):\n",
        "          lrlist = [1e-5]\n",
        "          expldecay = [0.002]\n",
        "        else:\n",
        "          lrlist = [1e-4]\n",
        "          expldecay = [0.02]\n",
        "        for LearningRate in lrlist:\n",
        "            for exploration_decay in expldecay: \n",
        "                optimizer = torch.optim.Adam(policy_net.parameters(), lr=LearningRate)\n",
        "                scheduler = optim.lr_scheduler.ExponentialLR(optimizer,gamma=LearningRateDecay)\n",
        "                loss = torch.nn.MSELoss()\n",
        "                def trainModel():\n",
        "                    if buffer.counter < BatchSize:\n",
        "                        return 0.0\n",
        "                    \n",
        "                    state_batch, action_batch, reward_batch, new_state_batch, done_batch = buffer.sample_buffer(BatchSize)\n",
        "\n",
        "                    q_actual = torch.gather(policy_net(state_batch),1,action_batch.reshape(-1,1))\n",
        "                    with torch.no_grad():\n",
        "                        if(arch == \"DoubleDQN\" or arch == \"DoubleDuelingDQN\"):\n",
        "                            target = torch.argmax(policy_net(state_batch), -1).detach()\n",
        "                            q_max_next = target_net(new_state_batch).gather(1, target.unsqueeze(-1)).squeeze(-1)\n",
        "                        else:\n",
        "                            q_max_next = target_net(new_state_batch).max(1)[0].detach()\n",
        "                    q_target = (q_max_next * discount_factor)*(1-done_batch) + reward_batch\n",
        "\n",
        "                    ll=loss(q_actual, q_target.unsqueeze(1))\n",
        "\n",
        "                    # Optimize the model\n",
        "                    optimizer.zero_grad()\n",
        "                    ll.backward()\n",
        "                    for param in policy_net.parameters():\n",
        "                        param.grad.data.clamp_(-1, 1)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    return ll.item();\n",
        "                file_name = mt.set_name(arch,n_layers,BatchSize,exploration_threshold,exploration_threshold_min,exploration_decay,discount_factor,LearningRate,LearningRateDecay)\n",
        "                file_path = mt.create_dir(file_path_,file_name)\n",
        "                mt.create_dir(file_path,\"Checkpoints\")\n",
        "                print(file_name)\n",
        "                bestNet, episodes, scores, events, avg_scores, avg_scores20, exploration, avg_scores100 = tl.train_loop(policy_net, target_net, env, device, TotalEpisodes, FreezeCounter, SaveAtCounter, createMovie, MaxSteps, exploration_threshold, exploration_decay, exploration_threshold_min, buffer, trainModel,file_path)\n",
        "\n",
        "                eval.performance_evaluation(file_path,episodes, scores, events, avg_scores, avg_scores20, exploration, avg_scores100)\n",
        "                eval.report(file_path,arch,BatchSize,exploration_threshold,exploration_threshold_min,exploration_decay,discount_factor,\n",
        "                            LearningRate,LearningRateDecay,episodes, scores, events, avg_scores, avg_scores20, exploration, n_layers,avg_scores100)\n",
        "                createMovie(bestNet,file_path,'bestNet')\n",
        "                time.sleep(1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of DeepRL_PartI_queue.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}