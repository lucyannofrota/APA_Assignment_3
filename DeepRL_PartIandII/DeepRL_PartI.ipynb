{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssxiwwi66Se3"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idJX2upP6O8W",
        "outputId": "af0cfcf7-ac74-4fa7-bf34-265362c01bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
            "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
            "Requirement already satisfied: gym[box2d]==0.17.* in /home/lucyannofrota/anaconda3/envs/APA/lib/python3.9/site-packages (0.17.3)\n",
            "Collecting pyvirtualdisplay==0.2.*\n",
            "  Using cached PyVirtualDisplay-0.2.5-py2.py3-none-any.whl (13 kB)\n",
            "Collecting PyOpenGL==3.1.*\n",
            "  Using cached PyOpenGL-3.1.5-py3-none-any.whl (2.4 MB)\n",
            "Collecting PyOpenGL-accelerate==3.1.*\n",
            "  Using cached PyOpenGL_accelerate-3.1.5-cp39-cp39-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.10.4 in /home/lucyannofrota/anaconda3/envs/APA/lib/python3.9/site-packages (from gym[box2d]==0.17.*) (1.20.3)\n",
            "Requirement already satisfied: scipy in /home/lucyannofrota/anaconda3/envs/APA/lib/python3.9/site-packages (from gym[box2d]==0.17.*) (1.7.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/lucyannofrota/anaconda3/envs/APA/lib/python3.9/site-packages (from gym[box2d]==0.17.*) (1.6.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/lucyannofrota/anaconda3/envs/APA/lib/python3.9/site-packages (from gym[box2d]==0.17.*) (1.5.0)\n",
            "Collecting box2d-py~=2.3.5\n",
            "  Using cached box2d-py-2.3.8.tar.gz (374 kB)\n",
            "Requirement already satisfied: EasyProcess in /home/lucyannofrota/anaconda3/envs/APA/lib/python3.9/site-packages (from pyvirtualdisplay==0.2.*) (0.3)\n",
            "Requirement already satisfied: future in /home/lucyannofrota/anaconda3/envs/APA/lib/python3.9/site-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]==0.17.*) (0.18.2)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
            "   command: /home/lucyannofrota/anaconda3/envs/APA/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-e2l8u9lm/box2d-py_ec461a5c34534b3ca36c83974d58a538/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-e2l8u9lm/box2d-py_ec461a5c34534b3ca36c83974d58a538/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-eex0h2bw\n",
            "       cwd: /tmp/pip-install-e2l8u9lm/box2d-py_ec461a5c34534b3ca36c83974d58a538/\n",
            "  Complete output (16 lines):\n",
            "  Using setuptools (version 58.0.4).\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-3.9\n",
            "  creating build/lib.linux-x86_64-3.9/Box2D\n",
            "  copying library/Box2D/__init__.py -> build/lib.linux-x86_64-3.9/Box2D\n",
            "  copying library/Box2D/Box2D.py -> build/lib.linux-x86_64-3.9/Box2D\n",
            "  creating build/lib.linux-x86_64-3.9/Box2D/b2\n",
            "  copying library/Box2D/b2/__init__.py -> build/lib.linux-x86_64-3.9/Box2D/b2\n",
            "  running build_ext\n",
            "  building 'Box2D._Box2D' extension\n",
            "  swigging Box2D/Box2D.i to Box2D/Box2D_wrap.cpp\n",
            "  swig -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library/Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D/Box2D_wrap.cpp Box2D/Box2D.i\n",
            "  error: command 'swig' failed: No such file or directory\n",
            "  ----------------------------------------\u001b[0m\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "Installing collected packages: box2d-py, pyvirtualdisplay, PyOpenGL-accelerate, PyOpenGL\n",
            "    Running setup.py install for box2d-py ... \u001b[?25lerror\n",
            "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
            "     command: /home/lucyannofrota/anaconda3/envs/APA/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-e2l8u9lm/box2d-py_ec461a5c34534b3ca36c83974d58a538/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-e2l8u9lm/box2d-py_ec461a5c34534b3ca36c83974d58a538/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-xnx7bbsl/install-record.txt --single-version-externally-managed --compile --install-headers /home/lucyannofrota/anaconda3/envs/APA/include/python3.9/box2d-py\n",
            "         cwd: /tmp/pip-install-e2l8u9lm/box2d-py_ec461a5c34534b3ca36c83974d58a538/\n",
            "    Complete output (16 lines):\n",
            "    Using setuptools (version 58.0.4).\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.9\n",
            "    creating build/lib.linux-x86_64-3.9/Box2D\n",
            "    copying library/Box2D/__init__.py -> build/lib.linux-x86_64-3.9/Box2D\n",
            "    copying library/Box2D/Box2D.py -> build/lib.linux-x86_64-3.9/Box2D\n",
            "    creating build/lib.linux-x86_64-3.9/Box2D/b2\n",
            "    copying library/Box2D/b2/__init__.py -> build/lib.linux-x86_64-3.9/Box2D/b2\n",
            "    running build_ext\n",
            "    building 'Box2D._Box2D' extension\n",
            "    swigging Box2D/Box2D.i to Box2D/Box2D_wrap.cpp\n",
            "    swig -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library/Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D/Box2D_wrap.cpp Box2D/Box2D.i\n",
            "    error: command 'swig' failed: No such file or directory\n",
            "    ----------------------------------------\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Command errored out with exit status 1: /home/lucyannofrota/anaconda3/envs/APA/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-e2l8u9lm/box2d-py_ec461a5c34534b3ca36c83974d58a538/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-e2l8u9lm/box2d-py_ec461a5c34534b3ca36c83974d58a538/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-xnx7bbsl/install-record.txt --single-version-externally-managed --compile --install-headers /home/lucyannofrota/anaconda3/envs/APA/include/python3.9/box2d-py Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "# install required system dependencies\n",
        "!apt-get install -y xvfb x11-utils\n",
        "\n",
        "# install required python dependencies (might need to install additional gym extras depending)\n",
        "!pip install gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1O4fl6bwGG_",
        "outputId": "b555e1ae-2aea-4089-e052-d4ecf0483257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "cuda:0\n",
            "mkdir: cannot create directory ‘Checkpoints’: File exists\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "import gym\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import random\n",
        "from gym import wrappers\n",
        "import copy\n",
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.cuda.is_available())\n",
        "print(device)\n",
        "\n",
        "from PartI_lib import archs as archs\n",
        "from PartI_lib import performance_evaluation as eval\n",
        "from PartI_lib import train_loop as tl\n",
        "from PartI_lib import my_tools as mt\n",
        "!mkdir Checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IIeU54J8wXkI"
      },
      "outputs": [],
      "source": [
        "#@title Deep RL Replay Buffer\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, size, input_shape,dev):\n",
        "        self.size = size\n",
        "        self.counter = 0\n",
        "        self.state_buffer = torch.zeros((self.size, input_shape))\n",
        "        self.action_buffer = torch.zeros(self.size, dtype=torch.int64)\n",
        "        self.reward_buffer = torch.zeros(self.size)\n",
        "        self.new_state_buffer = torch.zeros((self.size, input_shape))\n",
        "        self.terminal_buffer = torch.zeros(self.size)\n",
        "        self.state_buffer.to(dev)\n",
        "        self.action_buffer.to(dev)\n",
        "        self.reward_buffer.to(dev)\n",
        "        self.new_state_buffer.to(dev)\n",
        "        self.terminal_buffer.to(dev)\n",
        "        self.dev=dev;\n",
        "\n",
        "\n",
        "\n",
        "    def store_tuples(self, state, action, reward, new_state, done):\n",
        "        idx = self.counter % self.size\n",
        "        self.state_buffer[idx] = state\n",
        "        self.action_buffer[idx] = action\n",
        "        self.reward_buffer[idx] = reward\n",
        "        self.new_state_buffer[idx] = new_state\n",
        "        self.terminal_buffer[idx] = done\n",
        "        self.counter += 1\n",
        "\n",
        "    def sample_buffer(self, batch_size):\n",
        "        max_buffer = min(self.counter, self.size)\n",
        "        batch = np.random.choice(max_buffer, batch_size, replace=False)\n",
        "        state_batch = self.state_buffer[batch].to(self.dev)\n",
        "        action_batch = self.action_buffer[batch].to(self.dev)\n",
        "        reward_batch = self.reward_buffer[batch].to(self.dev)\n",
        "        new_state_batch = self.new_state_buffer[batch].to(self.dev)\n",
        "        done_batch = self.terminal_buffer[batch].to(self.dev)\n",
        "\n",
        "        return state_batch, action_batch, reward_batch, new_state_batch, done_batch\n",
        "    def last_buffer(self, batch_size):\n",
        "        state_batch = self.state_buffer[-1:-batch_size].to(self.dev)\n",
        "        action_batch = self.action_buffer[-1:-batch_size].to(self.dev)\n",
        "        reward_batch = self.reward_buffer[-1:-batch_size].to(self.dev)\n",
        "        new_state_batch = self.new_state_buffer[-1:-batch_size].to(self.dev)\n",
        "        done_batch = self.terminal_buffer[-1:-batch_size].to(self.dev)\n",
        "\n",
        "        return state_batch, action_batch, reward_batch, new_state_batch, done_batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG0T040FwczS"
      },
      "source": [
        "Default DQN arquitecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aGrl7mfpwgfM"
      },
      "outputs": [],
      "source": [
        "# class DQN(nn.Module):\n",
        "\n",
        "#     def __init__(self, inputs, outputs,dfactor):\n",
        "#         super(DQN, self).__init__()\n",
        "        \n",
        "#         self.input_size=inputs;\n",
        "#         self.output_size=outputs;\n",
        "#         self.discount_factor=dfactor;\n",
        "        \n",
        "#         self.layers = nn.Sequential(\n",
        "#             nn.Linear(in_features=self.input_size, out_features=128),\n",
        "#             # nn.Linear(in_features=128, out_features=256),\n",
        "#             # nn.Linear(in_features=256, out_features=512),\n",
        "#             # nn.Linear(in_features=512, out_features=256),\n",
        "#             nn.Linear(in_features=128, out_features=self.output_size)\n",
        "#         )\n",
        "\n",
        "\n",
        "#     # Called with either one element to determine next action, or a batch\n",
        "#     # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "#     def forward(self, x):\n",
        "#         return self.layers(x)\n",
        "\n",
        "#     def policy(self,state):\n",
        "#        with torch.no_grad():\n",
        "#             return self.__call__(state).argmax()\n",
        "     \n",
        "#     def getPolicy(self,state,eps_threshold):\n",
        "#         sample = random.random()\n",
        "#         if sample > eps_threshold:\n",
        "#             with torch.no_grad():\n",
        " \n",
        "#                 return self.__call__(state).argmax()\n",
        "#         else:\n",
        "#             return  torch.tensor([[random.randrange(self.output_size)]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9Cz-vtcwv1s"
      },
      "source": [
        "OpenAI Environment CartPole-v0\n",
        "\n",
        "###    Description:\n",
        "        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\n",
        "###    Source:\n",
        "        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\n",
        "###    Observation:\n",
        "        Type: Box(4)\n",
        "        Num     Observation               Min                     Max\n",
        "        0       Cart Position             -4.8                    4.8\n",
        "        1       Cart Velocity             -Inf                    Inf\n",
        "        2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
        "        3       Pole Angular Velocity     -Inf                    Inf\n",
        "###    Actions:\n",
        "        Type: Discrete(2)\n",
        "        Num   Action\n",
        "        0     Push cart to the left\n",
        "        1     Push cart to the right\n",
        "        Note: The amount the velocity that is reduced or increased is not fixed; it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it\n",
        "###    Reward:\n",
        "        Reward is 1 for every step taken, including the termination step\n",
        "###    Starting State:\n",
        "        All observations are assigned a uniform random value in [-0.05..0.05]\n",
        "###    Episode Termination:\n",
        "        Pole Angle is more than 12 degrees.\n",
        "        Cart Position is more than 2.4 (center of the cart reaches the edge of the display).\n",
        "        Episode length is greater than 200.\n",
        "###     Solved Requirements:\n",
        "        Considered solved when the average return is greater than or equal to 195.0 over 20 consecutive trials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "dVwFwJMNxoCw"
      },
      "outputs": [],
      "source": [
        "#@title DQN movie generation (for visual evaluation in Google Colab)\n",
        "def createMovie(Network,Filename):\n",
        "    env = gym.make(\"CartPole-v0\")\n",
        "    envX = wrappers.Monitor(env, './videos/'+Filename,force=True)\n",
        "\n",
        "    observation = envX.reset()\n",
        "\n",
        "    i=0\n",
        "    Network.eval()\n",
        "\n",
        "    while True:\n",
        "        envX.render()\n",
        "        \n",
        "        state=torch.Tensor(observation).to(device)\n",
        "      \n",
        "        action = Network.policy(state);\n",
        "             \n",
        "        observation, reward, done, info = envX.step(action.item()) \n",
        "        i=i+1;     \n",
        "        if done: \n",
        "          break;\n",
        "\n",
        "    envX.close()\n",
        "    env.close();\n",
        "    Network.train()\n",
        "    mp4list = glob.glob('./videos/'+Filename+'/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "    else: \n",
        "        print(\"Could not find video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7SRgxRm5Ti-"
      },
      "source": [
        "Run the new netwwork with random policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "Z0YCI9TL5Szv",
        "outputId": "7c9f00b2-80d3-4981-a5a9-fcd8e0c05d7a"
      },
      "outputs": [],
      "source": [
        "# randomnet=RandomNet(2)\n",
        "# createMovie(randomnet,\"random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsEv2cZLwy3e"
      },
      "source": [
        "Initialization and Parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yygleEXxEpG",
        "outputId": "6252a170-0e96-443e-f1eb-5fb7d078a71e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DQN(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
            "    (1): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "DQN_128_1_001_2e-03_099_1e-03_097\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Sim configuration\n",
        "env = gym.make(\"CartPole-v0\")\n",
        "spec = gym.spec(\"CartPole-v0\")\n",
        "\n",
        "\n",
        "\n",
        "inputs=4\n",
        "n_actions=2\n",
        "\n",
        "#hyper-parameters\n",
        "TotalEpisodes=1500\n",
        "MaxSteps=200\n",
        "FreezeCounter=25\n",
        "BatchSize=128\n",
        "exploration_threshold=1\n",
        "exploration_threshold_min=0.01\n",
        "exploration_decay=0.002\n",
        "discount_factor=0.99\n",
        "SaveAtCounter=999999\n",
        "LearningRate=0.001\n",
        "LearningRateDecay=0.97\n",
        "\n",
        "\n",
        "arch = \"DQN\"\n",
        "\n",
        "#network DQN\n",
        "policy_net, target_net = archs.archs(arch,inputs,n_actions,discount_factor,device)\n",
        "# policy_net = DQN(inputs, n_actions,discount_factor).to(device)\n",
        "# target_net = DQN(inputs, n_actions,discount_factor).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "buffer = ReplayBuffer(1000000, inputs,device);\n",
        "\n",
        "print(policy_net)\n",
        "\n",
        "optimizer = torch.optim.Adam(policy_net.parameters(), lr=LearningRate)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer,gamma=LearningRateDecay)\n",
        "loss = torch.nn.MSELoss()\n",
        "\n",
        "\n",
        "file_name = mt.set_name(arch,BatchSize,exploration_threshold,exploration_threshold_min,exploration_decay,discount_factor,LearningRate,LearningRateDecay)\n",
        "file_path = mt.create_dir(\"results\",file_name)\n",
        "print(file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVf5wZAHxOST"
      },
      "source": [
        "DQN training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IPMrYDxyxVT1"
      },
      "outputs": [],
      "source": [
        "def trainModel():\n",
        "    if buffer.counter < BatchSize:\n",
        "        return 0.0\n",
        "         \n",
        "    state_batch, action_batch, reward_batch, new_state_batch, done_batch = buffer.sample_buffer(BatchSize)\n",
        "\n",
        "    q_actual = torch.gather(policy_net(state_batch),1,action_batch.reshape(-1,1))\n",
        "    with torch.no_grad():\n",
        "        q_max_next = target_net(new_state_batch).max(1)[0].detach()\n",
        "    q_target = (q_max_next * discount_factor)*(1-done_batch) + reward_batch\n",
        "\n",
        "    ll=loss(q_actual, q_target.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    ll.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n",
        "\n",
        "    return ll.item();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiLK6ZG3xlUd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wv8KK14wxs5r",
        "outputId": "ba605ecb-9daa-4e8d-de80-2766bee910b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 of 1500\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22.0 22 22.0\n",
            "34.0 34 28.0\n",
            "38.0 38 26.75\n",
            "52.0 52 25.8\n",
            "25 of 1500\n",
            "50 of 1500\n",
            "75 of 1500\n",
            "100 of 1500\n",
            "125 of 1500\n",
            "150 of 1500\n",
            "175 of 1500\n",
            "200 of 1500\n",
            "53.0 53 19.9\n",
            "66.0 66 23.65\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_108410/1972727255.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# sys.path.insert(1, '/PartI_lib')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from PartI_lib import train_loop as tl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbestNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTotalEpisodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFreezeCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSaveAtCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreateMovie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxSteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration_threshold_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/APA_ws/APA_Assignment_3/DeepRL_PartIandII/PartI_lib/train_loop.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(policy_net, target_net, env, device, TotalEpisodes, FreezeCounter, SaveAtCounter, createMovie, MaxSteps, exploration_threshold, exploration_decay, exploration_threshold_min, buffer, trainModel)\u001b[0m\n\u001b[1;32m     32\u001b[0m               \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m           \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_108410/3242152386.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# import sys\n",
        "# sys.path.insert(1, '/PartI_lib')\n",
        "# from PartI_lib import train_loop as tl\n",
        "bestNet, episodes, scores, events, avg_scores, avg_scores20, exploration = tl.train_loop(policy_net, target_net, env, device, TotalEpisodes, FreezeCounter, SaveAtCounter, createMovie, MaxSteps, exploration_threshold, exploration_decay, exploration_threshold_min, buffer, trainModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qEpTPbGxu_M"
      },
      "source": [
        "Plot performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWwFBt0vxxEd"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "performance_evaluation() takes 6 positional arguments but 7 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_107026/2099795027.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformance_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_scores20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexploration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# BatchSize=128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: performance_evaluation() takes 6 positional arguments but 7 were given"
          ]
        }
      ],
      "source": [
        "# figure(figsize=(12, 6), dpi=80)\n",
        "# plt.plot(episodes, scores)\n",
        "# plt.plot(episodes, events)\n",
        "# plt.plot(episodes, avg_scores)\n",
        "# plt.plot(episodes, avg_scores20)\n",
        "# plt.plot(episodes, exploration)\n",
        "# plt.xlabel('episodes')\n",
        "# plt.ylabel('y axis label')\n",
        "# plt.title('Report')\n",
        "# plt.legend(['scores',  'events', 'avg_scores', 'avg_scores20','exploration'])\n",
        "# plt.show()\n",
        "\n",
        "eval.performance_evaluation(arch,episodes, scores, events, avg_scores, avg_scores20, exploration)\n",
        "\n",
        "# BatchSize=128\n",
        "# exploration_threshold=1\n",
        "# exploration_threshold_min=0.01\n",
        "# exploration_decay=0.002\n",
        "# discount_factor=0.99\n",
        "# LearningRate=0.001\n",
        "# LearningRateDecay=0.97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7IDgBVCx3mZ"
      },
      "source": [
        "View Best Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9RpF49oOsZj"
      },
      "outputs": [],
      "source": [
        "createMovie(bestNet,'bestNet')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DeepRL_PartI.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
